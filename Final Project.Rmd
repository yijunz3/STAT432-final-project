---
title: "STAT432 final project"
output: pdf_document
author: Yijun Zhao (yijunz3), Peiyi Chen (peiyic2), Rongxin Ni (rni4)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(tidyselect)
```


## Readin the Data

```{r}
  dataset = read.csv("brca_data_w_subtypes.csv")
  dataset
```

```{r}
  dim(dataset)
  # discard the vital.status variable
  data = subset(dataset, select = c(-vital.status))
  
  # separate outcomes from the training variables
  data_x = subset(data, select = c(-PR.Status, -ER.Status, 
                                               -HER2.Final.Status, 
                                               -histological.type))
  data_y = subset(data, select = c(PR.Status, ER.Status, 
                                               HER2.Final.Status, 
                                               histological.type))
  dim(data_x)
  dim(data_y)
```

## Summary Statistics and data processing

```{r}
  # Provide a summary of your data using univariate analysis
  library(psych)
  summary = describe(data_x)
  summary
```

Based on the description of data, we realize that there are four different omics data types: cn-copy number variations (n=860), mu-mutations (n=249), rs-gene expression (n=604) and pp-protein levels (n=223). Variables in the types of rs and pp are continous, while the rest of variables are categorical.

According to the article "Comprehensive Molecular Portraits of Invasive Lobular Breast Cancer", we know that mutations PTEN, TBX3, and FOXA1 are ILC enriched features, so these variables should definitely be included in our dataset. Moreover, there are Recurrently Mutated Genes in Breast Cancer given by this article, which should also be considered. We can remove other unrelated variables.

```{r}
data_continous = data_x %>%
  dplyr::select(matches("rs_"),matches("pp_"))

list = c('mu_PIK3CA','mu_RUNX1','mu_CDH1','mu_TP53','mu_TBX3','mu_PTEN','mu_FOXA1','mu_MAP3K1','mu_GATA3','mu_AKT1',"mu_NBL1",'mu_KMT2C','mu_DCTD','mu_RB1','mu_SF3B1','mu_CBFB','mu_ARHGAP35','mu_OR9A2','mu_NCOA3','mu_RBMX','mu_MAP2K4','mu_TROVE2','mu_NADK','mu_CASP8','mu_CTSS','mu_ACTL6B','mu_LGALS1','mu_KRAS','mu_KCNN3','mu_FBXW7','mu_LRIG2','mu_PIK3R1','mu_PARP4','mu_ZNF28','mu_HLA-DRB1','mu_ERBB2','mu_ZMYM3','mu_RAB42','mu_CTCF','mu_ATAD2','mu_CDKN1B','mu_GRIA2','mu_NCOR1','mu_HRNR','mu_GPRIN2','mu_PAX2','mu_ACTG1','mu_AQP12A','mu_PIK3C3','mu_MYB','mu_IRS4','mu_TBL1XR1','mu_RPGR','mu_CCNI','mu_ARID1A','mu_CD3EAP','mu_ADAMTS6','mu_OR2D2','mu_TMEM199','mu_MST1','mu_RHBG','mu_ZFP36L1','mu_TCP11','mu_CASZ1','mu_GAL3ST1','mu_FRMPD2','mu_GPS2','mu_ZNF362')

data_cat_1 = data_x %>%
  dplyr::select(matches(list))
data_cat_2 = data_x %>%
  dplyr::select(matches("cn_"))

data_cat = cbind(data_cat_1,data_cat_2)
dim(data_continous)
dim(data_cat)
```



```{r}
# For continuous predictors, is there any outlier/missing value? Do you need to do any transformations?

#Check for missing values, 需要注意的是，不确定0是不是missing value
sum(is.na(data_continous))

#Check for outlier values
outliers = boxplot(data_continous)$out
length(boxplot(data_continous)$out)


```

We have no missing values, but many outliers. We would consider remove these outliers. 

```{r}

```


Next, we will check the distribution of continuous variables.

```{r}
#Check the histogram of first and last 5 continuous variables
for (i in c(1:5,822:827)) {
  hist(data_continous[,i], xlab = colnames(data_continous)[i])
}

```

Although some variables are skewed, we can observe that the majority of variables are normally distributed. Therefore, transformation is unnecessary.

We will also check the correlation between continuous variables and


```{r}
  # For continuous predictors, is there any outlier/missing value? Do you need to do any transformations?
  # which(colnames(data_x) == "cn_ISG15")
  ### 会hurt performance
  #continuous_data = data_x[1:604]
  #summary = describe(continuous_data)
  #skew_idx = which(abs(summary$skew) > 1)
  #length(skew_idx)
  # number of missing values
  #nrow(continuous_data) - nrow(na.omit(continuous_data)) 
  # number of outlier values
  #length(boxplot(continuous_data)$out)
  
  #for (i in skew_idx) {
    #shift = 0
    #if (summary$min[i] <= 0) {
      #shift = 1
    #}
    #hist(continuous_data[,i], breaks = 10, main = colnames(continuous_data)[i])
    #continuous_data[,i] <- log(shift + continuous_data[,i])
  #}
  data_x = cbind(data_continous,data_cat)
dim(data_x)
  
  
```


There also exists many unbalanced categorical data, see the following examples.

```{r}

  # For categorical predictors, do you need to deal with variables that are extremely unbalanced?
  #categorical_data = data_x[,605:1936]
  for (i in 1:10){
    print(table(data_cat[,i]))
    
  }

#We can try to deal with the first unbalanced variable


```



```{r}
  # Any variable/observation you decided to remove from the analysis? And for what reason?



  # You need to provide tables and/or figures to properly display the information to support your decision and clearly document your processing steps.

```

```{r}
  data_x = cbind(data_continous,data_cat)
  # separate train & test data
  set.seed(12345)
  # 75% of the sample size
  smp_size <- floor(0.75 * nrow(data))
  train_idxes <- sample(seq_len(nrow(data)), size = smp_size, replace = FALSE, prob = NULL)
  train_data_x <- data_x[train_idxes,]
  test_data_x <- data_x[-train_idxes,]
  train_data_y <- data_y[train_idxes,]
  test_data_y <- data_y[-train_idxes,]
  
  dim(train_data_x)
  dim(train_data_y)
  
  dim(test_data_x)
  dim(test_data_y)
  
  # preprocess by outcome value
  preprocess <- function(data_x, data_y_type, 
                          class1="Positive", class2="Negative") {
    idxes = which(data_y_type %in% c(class1, class2))
    x = data_x[idxes, ]
    y = data_y_type[idxes]
    # class1 = 1, class2 = 0
    y = as.factor(y)
    y = as.numeric(y) - 1
    print(dim(x))
    print(length(y))
  
    return(list("x" = x,  "y" = y, "idxes"=idxes))
  }

```

## Build a classification model to predict PR.Status. 

Let's first take a look of the data.

```{r}
#data_pr = data %>%
  #select(-c('ER.Status'))

table(data$PR.Status)
```

There exists 122 missing values should be removed, classes "Indeterminate", "Not Performed" and "Performed but Not Available" contain few value, so we will only focus on classes "Positive" and "Negative". 

```{r}
  pr_data_train = preprocess(train_data_x, train_data_y$PR.Status)
  pr_data_test = preprocess(test_data_x, test_data_y$PR.Status)
  
```


### Approach 1 (lda)
```{r}

library(MASS)
dig.lda = lda(pr_data_train$x,pr_data_train$y)
  # Use classification error as the evaluation criterion.
Ytest.pred = predict(dig.lda, pr_data_test$x)
mean(pr_data_test$y != Ytest.pred$class)  
  # You need to provide sufficient information (table, figure and descriptions) to demonstrate the model fitting results
table(pr_data_test$y, Ytest.pred$class)

```

### Approach 2 (Kmeans)
```{r}
set.seed(12345)
pr_mat_train = cbind(pr_data_train$x,pr_data_train$y)
kmeanfit <- kmeans(pr_mat_train[,-1], 2)


  # Use classification error as the evaluation criterion.
mean((pr_mat_train$`pr_data_train$y` + 1) != kmeanfit$cluster)

  # You need to provide sufficient information (table, figure and descriptions) to demonstrate the model fitting results
table(pr_mat_train$`pr_data_train$y`, kmeanfit$cluster)

```

## Build a classification model to predict histological.type 

```{r}
  hist_data_train = preprocess(train_data_x, 
                          train_data_y$histological.type, 
                          class1 = "infiltrating lobular carcinoma", 
                          class2 = "infiltrating ductal carcinoma")
  hist_data_test = preprocess(test_data_x, 
                          test_data_y$histological.type,
                          class1 = "infiltrating lobular carcinoma", 
                          class2 = "infiltrating ductal carcinoma")
  
```
### Approach 1 (Logistic Regression)

```{r}
  library(glmnet)
  logistic.fit <- glmnet(hist_data_train$x, hist_data_train$y, alpha = 0, family = "binomial")
  pred = predict(logistic.fit, data.matrix(hist_data_test$x), type = "response", s=min(logistic.fit$lambda))
  
  # Use AUC as the evaluation criterion.
  library(ROCR)
  roc <- prediction(pred, hist_data_test$y)
  performance(roc, measure = "auc")@y.values[[1]]
  
  # calculates the ROC curve
  perf <- performance(roc,"tpr","fpr")
  plot(perf,colorize=TRUE)
  
  # You need to provide sufficient information (table, figure and descriptions) to demonstrate the model fitting results
  table(pred > 0.5, hist_data_test$y)
```

### Approach 2 (SVM)

```{r}
  library(e1071)
  svm.fit <- svm(as.factor(hist_data_train$y) ~ ., 
                  data = data.frame(hist_data_train$x), 
                  type='C-classification',
                  probability = TRUE,
                  kernel='linear', scale=FALSE, cost = 1)
  
  pred = predict(svm.fit, hist_data_test$x, probability=TRUE)
  pred_prob = attr(pred, "probabilities")
  
  # Use AUC as the evaluation criterion.
  roc <- prediction(pred_prob[,2], hist_data_test$y)
  performance(roc, measure = "auc")@y.values[[1]]
  
  # calculates the ROC curve
  perf <- performance(roc,"tpr","fpr")
  plot(perf,colorize=TRUE)
  
  # You need to provide sufficient information (table, figure and descriptions) to demonstrate the model fitting results
  table(pred_prob[,2] > 0.5, hist_data_test$y)
```

## Variable selection for all outcomes

```{r}
  # preprocess by outcome value
  pr_data = preprocess(data_x, data_y$PR.Status)

  er_data = preprocess(data_x, data_y$ER.Status)

  her_data = preprocess(data_x, data_y$HER2.Final.Status)
  
  hist_data = preprocess(data_x, data_y$histological.type,
                          class1 = "infiltrating lobular carcinoma", 
                          class2 = "infiltrating ductal carcinoma")
```

```{r}
  # tune rf parameters
  library(caret)
  tunegrid <- expand.grid(mtry = c(50, 100, 500, 700),min.node.size = c(1,5,10,20),
                          splitrule = "gini")
  ctrl <- trainControl(method = "cv", number = 3)
  rf.fit = train(y=as.factor(hist_data$y), 
                    x = hist_data$x, method = 'ranger', 
                    trControl = ctrl, num.trees = 400, tuneGrid = tunegrid,
                    respect.unordered.factors = "partition")
  rf.fit
  pred = predict(rf.fit, hist_data$x)
  
  roc <- prediction(as.numeric(pred), as.numeric(hist_data$y))
  performance(roc, measure = "auc")@y.values[[1]]
  
  table(pred, hist_data$y)
```

```{r}
  # select a total of 50 variables
  library(randomForest)
  rf.fit_pr = randomForest(pr_data$x, as.factor(pr_data$y), ntree = 400, 
                        mtry = 500, nodesize = 1)
  rf.fit_er = randomForest(er_data$x, as.factor(er_data$y), ntree = 400, 
                        mtry = 500, nodesize = 1)
  rf.fit_her = randomForest(her_data$x, as.factor(her_data$y), ntree = 400, 
                        mtry = 500, nodesize = 1)
  rf.fit_hist = randomForest(hist_data$x, as.factor(hist_data$y), ntree = 400, 
                        mtry = 500, nodesize = 1)
  total_importance = rf.fit_pr$importance + rf.fit_er$importance + rf.fit_her$importance + rf.fit_hist$importance
  idxes = sort(total_importance, decreasing = TRUE, index.return=TRUE)$ix[1:50]
  pr_data$x = pr_data$x[idxes]
  er_data$x = er_data$x[idxes]
  her_data$x = her_data$x[idxes]
  hist_data$x = hist_data$x[idxes]
  dim(pr_data$x)
  dim(er_data$x)
  dim(her_data$x)
  dim(hist_data$x)
```

```{r}
  # evaluation criteria is based on a three-fold cross-validation with AUC for each outcome, and then average the cross-validated AUC of all four outcomes
  set.seed(1)
  all_fold_ids = sample(1:3, 705, replace = TRUE)
  
  eval <- function(data_x, data_y, fold_ids) {
    auc_list = c()
    for (i in 1:3) {
      test_idxes <- which(fold_ids==i)
      test_x <- data_x[test_idxes,]
      test_y <- data_y[test_idxes]
      train_x <- data_x[-test_idxes,]
      train_y <- data_y[-test_idxes]

      fit <- glmnet(train_x, as.factor(train_y), alpha = 0, family = "binomial")
      pred = predict(fit, data.matrix(test_x), type = "response", s=min(fit$lambda))
      roc <- prediction(pred, test_y)
      
      auc <- performance(roc, measure = "auc")@y.values[[1]]
      auc_list = c(auc_list, auc)
    }
    return(mean(auc_list))
  }

```


```{r}
  # must generate the fold ID (for all 705 observations) using the following code
  set.seed(1)
  fold_id_list = sample(1:3, 705, replace = TRUE)
  
  pr_auc = eval(pr_data$x, pr_data$y, all_fold_ids[pr_data$idxes])
  er_auc = eval(er_data$x, er_data$y, all_fold_ids[er_data$idxes])
  her_auc = eval(her_data$x, her_data$y, all_fold_ids[her_data$idxes])
  hist_auc = eval(hist_data$x, hist_data$y, all_fold_ids[hist_data$idxes])
  
  res = mean(c(pr_auc, hist_auc, er_auc, her_auc))
  
  pr_auc
  er_auc
  her_auc
  hist_auc
  res
```

```{r}
  colnames(pr_data$x)  
```
